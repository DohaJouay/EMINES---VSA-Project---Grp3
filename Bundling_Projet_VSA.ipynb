{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abirharrasse/EMINES---VSA-Project---Grp3/blob/master/Bundling_Projet_VSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "6Oa7EKVhynnu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKf0TFJkv7iq",
        "outputId": "00bf12f1-42aa-4568-ef66-9ef1d0911979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Hyperdimensional-Computing'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 96 (delta 14), reused 7 (delta 7), pack-reused 75 (from 1)\u001b[K\n",
            "Receiving objects: 100% (96/96), 48.20 MiB | 14.60 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Updating files: 100% (13/13), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone  https://github.com/abirharrasse/Hyperdimensional-Computing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7uW70Yb31gt",
        "outputId": "1d9dd5c1-97fd-47ee-b52c-bfc880c84707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Hyperdimensional-Computing\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Hyperdimensional-Computing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFemuk-62FV3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from utils import prepare_data, encode_and_save\n",
        "from model import BModel, GModel\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UztSSu0RpNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a2d25f4-19c9-4dc5-a512-b6c086d5206b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "encoded_data_folder = '/content/drive/MyDrive/encoded_data'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pAg0tXhbJKR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d360effe-8ad4-454d-f9b4-14fbc35ccb30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed: 43\n",
            "Torch manual seed set successfully.\n"
          ]
        }
      ],
      "source": [
        "class ArgumentParser:\n",
        "    def __init__(self):\n",
        "        self.args = {\n",
        "            'lr': 0.01,            # Learning rate\n",
        "            'gamma': 0.3,          # Kernel parameter\n",
        "            'epoch': 1,            # Number of epochs\n",
        "            'gorder': 8,           # Group order\n",
        "            'dim': 10000,          # Dimension of hypervectors\n",
        "            'seed': 43,            # Random seed\n",
        "            'r': 2,\n",
        "            'resume': False,       # Resume flag\n",
        "            'data_dir': '/content/drive/MyDrive/encoded_data', # Data directory\n",
        "            'dataset': 'fmnist',   # Dataset name\n",
        "            'raw_data_dir': './dataset',  # Raw data directory\n",
        "            'model': 'rff-gvsa'    # Model type\n",
        "        }\n",
        "        # Dynamically set attributes on the instance\n",
        "        for key, value in self.args.items():\n",
        "            setattr(self, key, value)\n",
        "\n",
        "    def get_args(self):\n",
        "        return self.args\n",
        "\n",
        "# Instantiate the parser\n",
        "args = ArgumentParser()\n",
        "\n",
        "# Verify that attributes are correctly set\n",
        "print(f\"Seed: {args.seed}\")  # Should print \"Seed: 43\"\n",
        "\n",
        "# Use the seed with torch\n",
        "torch.manual_seed(args.seed)\n",
        "print(\"Torch manual seed set successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding with RFE"
      ],
      "metadata": {
        "id": "AVkGOuJVyjFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of datasets to iterate over\n",
        "dataset_choices = ['fmnist', 'mnist', 'isolet', 'ucihar']\n",
        "\n",
        "\n",
        "if 'hdc' in args.model:\n",
        "    args.gorder = 2\n",
        "    print(\"Use binary HDC with random fourier features, ignoring gorder, set to 2.\")\n",
        "\n",
        "# Loop over each dataset\n",
        "for dataset in dataset_choices:\n",
        "    # Set the current dataset in the args\n",
        "    args.dataset = dataset\n",
        "    args.data_dir = f'{args.data_dir}/{args.dataset}_{args.model}_order{args.gorder}_gamma{args.gamma}_dim{args.dim}'\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    try:\n",
        "        os.makedirs(args.data_dir)\n",
        "    except FileExistsError:\n",
        "        print(f'Encoded data folder for {dataset} already exists')\n",
        "\n",
        "    # Perform encoding and saving if not resuming from existing data\n",
        "    if not args.resume:\n",
        "        print(f'Encoding the dataset: {dataset}')\n",
        "        encode_and_save(args)\n",
        "        print(f'Finished encoding and saving for {dataset}')\n"
      ],
      "metadata": {
        "id": "lBvKygohItjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating accuracy of RFF with bundling and angular similarity"
      ],
      "metadata": {
        "id": "jJ4o01BbywDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from encoder import RandomFourierEncoder\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "dataset_choices = ['fmnist', 'mnist', 'isolet', 'ucihar']\n",
        "results = {}\n",
        "\n",
        "start = '/content/drive/MyDrive/encoded_data'\n",
        "# Loop over each dataset\n",
        "for dataset in dataset_choices:\n",
        "    args.dataset = dataset\n",
        "    args.data_dir = f'{start}/{args.dataset}_{args.model}_order{args.gorder}_gamma{args.gamma}_dim{args.dim}'\n",
        "\n",
        "    # Load the encoded training data\n",
        "    X_train = torch.load(f'{args.data_dir}/train_hd.pt')\n",
        "    y_train = torch.load(f'{args.data_dir}/y_train.pt')\n",
        "\n",
        "    # Load the encoded test data\n",
        "    X_test = torch.load(f'{args.data_dir}/test_hd.pt')\n",
        "    y_test = torch.load(f'{args.data_dir}/y_test.pt')\n",
        "    if len(X_train.shape) == 3:\n",
        "        X_train = X_train.squeeze(1)\n",
        "    if len(X_test.shape) == 3:\n",
        "        X_test = X_test.squeeze(1)\n",
        "\n",
        "    rfe = RandomFourierEncoder(input_dim=784, gamma=args.gamma, gorder=args.gorder, output_dim=args.dim)\n",
        "\n",
        "    # Compute the bundled vectors for each class\n",
        "    num_classes = torch.unique(y_train).size(0)\n",
        "    bundled_vectors = []\n",
        "    for c in range(num_classes):\n",
        "        class_data = torch.stack([X_train[i] for i in range(len(X_train)) if y_train[i] == c])\n",
        "        if len(class_data.shape) == 3:\n",
        "            class_data = class_data.squeeze(1)\n",
        "\n",
        "        bundled_vector = rfe.group_bundle(class_data)\n",
        "        bundled_vectors.append(bundled_vector)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i in tqdm(range(len(X_test)), desc=f\"Evaluating {dataset}\"):\n",
        "        x = X_test[i]\n",
        "\n",
        "        similarities = [rfe.similarity(x, bundled_vector) for bundled_vector in bundled_vectors]\n",
        "        predicted_class = similarities.index(max(similarities))\n",
        "        if predicted_class == y_test[i]:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    print(f'{dataset} Test Accuracy: {accuracy:.2f}%')\n",
        "    results[dataset] = accuracy\n",
        "\n",
        "# Print summary of accuracies\n",
        "print(f\"Summary of accuracies for {dataset} dataset: \")\n",
        "for dataset, accuracy in results.items():\n",
        "    print(f'{dataset}: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "bS4Bi2_8MNeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767cdfd8-7fa1-4550-c9a9-8111224baf69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-e858472512e0>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X_train = torch.load(f'{args.data_dir}/train_hd.pt')\n",
            "<ipython-input-7-e858472512e0>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  y_train = torch.load(f'{args.data_dir}/y_train.pt')\n",
            "<ipython-input-7-e858472512e0>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X_test = torch.load(f'{args.data_dir}/test_hd.pt')\n",
            "<ipython-input-7-e858472512e0>:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  y_test = torch.load(f'{args.data_dir}/y_test.pt')\n",
            "Evaluating fmnist: 100%|██████████| 10000/10000 [01:12<00:00, 137.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fmnist Test Accuracy: 73.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating mnist: 100%|██████████| 10000/10000 [01:12<00:00, 137.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mnist Test Accuracy: 84.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating isolet: 100%|██████████| 1559/1559 [00:32<00:00, 48.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "isolet Test Accuracy: 87.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ucihar: 100%|██████████| 2947/2947 [00:13<00:00, 222.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ucihar Test Accuracy: 80.42%\n",
            "Summary of accuracies for ucihar dataset: \n",
            "fmnist: 73.17%\n",
            "mnist: 84.46%\n",
            "isolet: 87.56%\n",
            "ucihar: 80.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding with ManhattanEncoder (see the github repo for the implementation)"
      ],
      "metadata": {
        "id": "y5rSLBrVy5U_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_manhattan import encode_and_save\n",
        "dataset_choices = ['isolet', 'ucihar']\n",
        "\n",
        "args.r = 12\n",
        "args.model = 'manhattan-hdc'\n",
        "print(\"Use binary HDC with manhattan distance\")\n",
        "start = '/content/drive/MyDrive/encoded_data'\n",
        "# Loop over each dataset\n",
        "for dataset in dataset_choices:\n",
        "    # Set the current dataset in the args\n",
        "    args.dataset = dataset\n",
        "    args.data_dir = f'{start}/{args.dataset}_{args.model}_order{args.r}_gamma{args.gamma}_dim{args.dim}'\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    try:\n",
        "        os.makedirs(args.data_dir)\n",
        "    except FileExistsError:\n",
        "        print(f'Encoded data folder for {dataset} already exists')\n",
        "\n",
        "    # Perform encoding and saving if not resuming from existing data\n",
        "    if not args.resume:\n",
        "        print(f'Encoding the dataset: {dataset}')\n",
        "        encode_and_save(args)\n",
        "        print(f'Finished encoding and saving for {dataset}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUdPhPLRNUlk",
        "outputId": "ea1d56bd-0b27-4384-886b-bb03f9df9ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use binary HDC with manhattan distance\n",
            "Encoded data folder for isolet already exists\n",
            "Encoding the dataset: isolet\n",
            "Loading dataset...\n",
            "# of channels of data 1\n",
            "# of training samples and test samples 6238 1559\n",
            "Encoding to HDC with Manhattan distance.\n",
            "Building item memory...\n",
            "generating linear item memory...\n",
            "Encoded pixels to hypervectors with size: torch.Size([256, 10000])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding training data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Data Encoding: 100%|██████████| 6238/6238 [14:11<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding test data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Data Encoding: 100%|██████████| 1559/1559 [03:28<00:00,  7.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished encoding and saving for isolet\n",
            "Encoding the dataset: ucihar\n",
            "Loading dataset...\n",
            "# of channels of data 1\n",
            "# of training samples and test samples 7352 2947\n",
            "Encoding to HDC with Manhattan distance.\n",
            "Building item memory...\n",
            "generating linear item memory...\n",
            "Encoded pixels to hypervectors with size: torch.Size([256, 10000])\n",
            "Encoding training data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Data Encoding: 100%|██████████| 7352/7352 [14:36<00:00,  8.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding test data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Data Encoding: 100%|██████████| 2947/2947 [05:56<00:00,  8.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished encoding and saving for ucihar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluationg the Accuracy with ManhattanEncoder, bundling and Manhattan Similarity: r = 2"
      ],
      "metadata": {
        "id": "_jFUEWC5zE1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from encoder_manhattan import ManhattanEncoder\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "dataset_choices = ['isolet', 'ucihar']\n",
        "results = {}\n",
        "args.r = 2\n",
        "start = '/content/drive/MyDrive/encoded_data'\n",
        "# Loop over each dataset\n",
        "for dataset in dataset_choices:\n",
        "    args.dataset = dataset\n",
        "    args.data_dir = f'{start}/{args.dataset}_{args.model}_order{args.r}_gamma{args.gamma}_dim{args.dim}'\n",
        "\n",
        "    # Load the encoded training data\n",
        "    X_train = torch.load(f'{args.data_dir}/train_hd.pt')\n",
        "    y_train = torch.load(f'{args.data_dir}/y_train.pt')\n",
        "\n",
        "    # Load the encoded test data\n",
        "    X_test = torch.load(f'{args.data_dir}/test_hd.pt')\n",
        "    y_test = torch.load(f'{args.data_dir}/y_test.pt')\n",
        "    if len(X_train.shape) == 3:\n",
        "        X_train = X_train.squeeze(1)\n",
        "    if len(X_test.shape) == 3:\n",
        "        X_test = X_test.squeeze(1)\n",
        "\n",
        "\n",
        "    mht = ManhattanEncoder(num=256, r=2)\n",
        "\n",
        "    # Compute the bundled vectors for each class\n",
        "    num_classes = torch.unique(y_train).size(0)\n",
        "    bundled_vectors = []\n",
        "    for c in range(num_classes):\n",
        "        class_data = torch.stack([X_train[i] for i in range(len(X_train)) if y_train[i] == c])\n",
        "        bundled_vector = mht.group_bundle(class_data)  # Use the instance method\n",
        "        bundled_vectors.append(bundled_vector)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i in tqdm(range(len(X_test))):\n",
        "        x = X_test[i]\n",
        "        similarities = [mht.similarity(x, bundled_vector) for bundled_vector in bundled_vectors]\n",
        "        predicted_class = similarities.index(max(similarities))\n",
        "        if predicted_class == y_test[i]:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "        accuracy = correct / total * 100\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "    results[dataset] = accuracy\n",
        "\n",
        "# Print summary of accuracies\n",
        "print(f\"Summary of accuracies for {dataset} dataset: \")\n",
        "for dataset, accuracy in results.items():\n",
        "    print(f'{dataset}: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXRyV_VPy9Cn",
        "outputId": "e49d6582-6d61-4f3b-88fc-c3d36a9663ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-dbc1dd45ea50>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X_train = torch.load(f'{args.data_dir}/train_hd.pt')\n",
            "<ipython-input-10-dbc1dd45ea50>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  y_train = torch.load(f'{args.data_dir}/y_train.pt')\n",
            "<ipython-input-10-dbc1dd45ea50>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X_test = torch.load(f'{args.data_dir}/test_hd.pt')\n",
            "<ipython-input-10-dbc1dd45ea50>:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  y_test = torch.load(f'{args.data_dir}/y_test.pt')\n",
            "100%|██████████| 1559/1559 [00:06<00:00, 226.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 3.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2947/2947 [00:03<00:00, 942.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 15.98%\n",
            "Summary of accuracies for ucihar dataset: \n",
            "isolet: 3.85%\n",
            "ucihar: 15.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With r = 12"
      ],
      "metadata": {
        "id": "TalPocDmzUDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from encoder_manhattan import ManhattanEncoder\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "dataset_choices = ['isolet', 'ucihar']\n",
        "results = {}\n",
        "\n",
        "start = '/content/drive/MyDrive/encoded_data'\n",
        "# Loop over each dataset\n",
        "for dataset in dataset_choices:\n",
        "    args.dataset = dataset\n",
        "    args.data_dir = f'{start}/{args.dataset}_{args.model}_order{args.r}_gamma{args.gamma}_dim{args.dim}'\n",
        "\n",
        "    # Load the encoded training data\n",
        "    X_train = torch.load(f'{args.data_dir}/train_hd.pt')\n",
        "    y_train = torch.load(f'{args.data_dir}/y_train.pt')\n",
        "\n",
        "    # Load the encoded test data\n",
        "    X_test = torch.load(f'{args.data_dir}/test_hd.pt')\n",
        "    y_test = torch.load(f'{args.data_dir}/y_test.pt')\n",
        "    if len(X_train.shape) == 3:\n",
        "        X_train = X_train.squeeze(1)\n",
        "    if len(X_test.shape) == 3:\n",
        "        X_test = X_test.squeeze(1)\n",
        "\n",
        "\n",
        "    mht = ManhattanEncoder(num=256, r=12)\n",
        "\n",
        "    # Compute the bundled vectors for each class\n",
        "    num_classes = torch.unique(y_train).size(0)\n",
        "    bundled_vectors = []\n",
        "    for c in range(num_classes):\n",
        "        class_data = torch.stack([X_train[i] for i in range(len(X_train)) if y_train[i] == c])\n",
        "        bundled_vector = mht.group_bundle(class_data)  # Use the instance method\n",
        "        bundled_vectors.append(bundled_vector)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i in tqdm(range(len(X_test))):\n",
        "        x = X_test[i]\n",
        "        similarities = [mht.similarity(x, bundled_vector) for bundled_vector in bundled_vectors]\n",
        "        predicted_class = similarities.index(max(similarities))\n",
        "        if predicted_class == y_test[i]:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "        accuracy = correct / total * 100\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "    results[dataset] = accuracy\n",
        "\n",
        "# Print summary of accuracies\n",
        "print(f\"Summary of accuracies for {dataset} dataset: \")\n",
        "for dataset, accuracy in results.items():\n",
        "    print(f'{dataset}: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbQgJoX2dMw_",
        "outputId": "670d71a1-936d-472a-ef58-1629775b315b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-cbf7975af5ba>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X_train = torch.load(f'{args.data_dir}/train_hd.pt')\n",
            "<ipython-input-9-cbf7975af5ba>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  y_train = torch.load(f'{args.data_dir}/y_train.pt')\n",
            "<ipython-input-9-cbf7975af5ba>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X_test = torch.load(f'{args.data_dir}/test_hd.pt')\n",
            "<ipython-input-9-cbf7975af5ba>:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  y_test = torch.load(f'{args.data_dir}/y_test.pt')\n",
            "100%|██████████| 1559/1559 [00:08<00:00, 178.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 3.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2947/2947 [00:03<00:00, 947.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 18.32%\n",
            "Summary of accuracies for ucihar dataset: \n",
            "isolet: 3.91%\n",
            "ucihar: 18.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwA3XXaDEaLh",
        "outputId": "c68c6a72-cb96-4c3f-8e29-311f4ff94d6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-b166f06e13f6>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X_train = torch.load(f'{args.data_dir}/{args.dataset}_{args.model}_order{args.gorder}_gamma{args.gamma}_dim{args.dim}/train_hd.pt')\n",
            "<ipython-input-12-b166f06e13f6>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  y_train = torch.load(f'{args.data_dir}/{args.dataset}_{args.model}_order{args.gorder}_gamma{args.gamma}_dim{args.dim}/y_train.pt')\n",
            "<ipython-input-12-b166f06e13f6>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X_test = torch.load(f'{args.data_dir}/{args.dataset}_{args.model}_order{args.gorder}_gamma{args.gamma}_dim{args.dim}/test_hd.pt')\n",
            "<ipython-input-12-b166f06e13f6>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  y_test = torch.load(f'{args.data_dir}/{args.dataset}_{args.model}_order{args.gorder}_gamma{args.gamma}_dim{args.dim}/y_test.pt')\n",
            "100%|██████████| 10000/10000 [00:27<00:00, 359.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 11.15%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from encoder_manhattan import ManhattanEncoder\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "args = ArgumentParser()\n",
        "torch.manual_seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "\n",
        "# Load the encoded training data\n",
        "X_train = torch.load(f'{args.data_dir}/{args.dataset}_{args.model}_order{args.gorder}_gamma{args.gamma}_dim{args.dim}/train_hd.pt')\n",
        "y_train = torch.load(f'{args.data_dir}/{args.dataset}_{args.model}_order{args.gorder}_gamma{args.gamma}_dim{args.dim}/y_train.pt')\n",
        "\n",
        "# Load the encoded test data\n",
        "X_test = torch.load(f'{args.data_dir}/{args.dataset}_{args.model}_order{args.gorder}_gamma{args.gamma}_dim{args.dim}/test_hd.pt')\n",
        "y_test = torch.load(f'{args.data_dir}/{args.dataset}_{args.model}_order{args.gorder}_gamma{args.gamma}_dim{args.dim}/y_test.pt')\n",
        "\n",
        "\n",
        "mht = ManhattanEncoder(num=10, r=8)\n",
        "\n",
        "# Compute the bundled vectors for each class\n",
        "num_classes = torch.unique(y_train).size(0)\n",
        "bundled_vectors = []\n",
        "for c in range(num_classes):\n",
        "    class_data = torch.stack([X_train[i] for i in range(len(X_train)) if y_train[i] == c])\n",
        "    bundled_vector = mht.group_bundle(class_data)  # Use the instance method\n",
        "    bundled_vectors.append(bundled_vector)\n",
        "\n",
        "# Evaluate on the test set\n",
        "correct = 0\n",
        "total = 0\n",
        "for i in tqdm(range(len(X_test))):\n",
        "    x = X_test[i]\n",
        "    similarities = [mht.similarity(x, bundled_vector) for bundled_vector in bundled_vectors]\n",
        "    predicted_class = similarities.index(max(similarities))\n",
        "    if predicted_class == y_test[i]:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "print(f'Test Accuracy: {correct / total * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating accuracy after RFF, bundling and Manhattan Similarity"
      ],
      "metadata": {
        "id": "cpFZm3qVzcS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from encoder_manhattan import ManhattanEncoder, RandomFourierEncoder\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "dataset_choices = ['fmnist', 'mnist', 'isolet', 'ucihar']\n",
        "results = {}\n",
        "args.r = 2\n",
        "args.gorder = 8\n",
        "args.model = 'rff-gvsa'\n",
        "print(\"Use binary HDC with manhattan distance\")\n",
        "start = '/content/drive/MyDrive/encoded_data'\n",
        "# Loop over each dataset\n",
        "for dataset in dataset_choices:\n",
        "    args.dataset = dataset\n",
        "    args.data_dir = f'{start}/{args.dataset}_{args.model}_order{args.gorder}_gamma{args.gamma}_dim{args.dim}'\n",
        "    print(args.data_dir)\n",
        "    # Load the encoded training data\n",
        "    X_train = torch.load(f'{args.data_dir}/train_hd.pt')\n",
        "    y_train = torch.load(f'{args.data_dir}/y_train.pt')\n",
        "\n",
        "    # Load the encoded test data\n",
        "    X_test = torch.load(f'{args.data_dir}/test_hd.pt')\n",
        "    y_test = torch.load(f'{args.data_dir}/y_test.pt')\n",
        "    if len(X_train.shape) == 3:\n",
        "        X_train = X_train.squeeze(1)\n",
        "    if len(X_test.shape) == 3:\n",
        "        X_test = X_test.squeeze(1)\n",
        "\n",
        "\n",
        "    mht = ManhattanEncoder(num=256, r=8)\n",
        "\n",
        "    rfe = RandomFourierEncoder(input_dim=784, gamma=args.gamma, gorder=args.gorder, output_dim=args.dim)\n",
        "\n",
        "    # Compute the bundled vectors for each class\n",
        "    num_classes = torch.unique(y_train).size(0)\n",
        "    bundled_vectors = []\n",
        "    for c in range(num_classes):\n",
        "        class_data = torch.stack([X_train[i] for i in range(len(X_train)) if y_train[i] == c])\n",
        "        if len(class_data.shape) == 3:\n",
        "            class_data = class_data.squeeze(1)\n",
        "\n",
        "        bundled_vector = rfe.group_bundle(class_data)\n",
        "        bundled_vectors.append(bundled_vector)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i in tqdm(range(len(X_test))):\n",
        "        x = X_test[i]\n",
        "        similarities = [mht.similarity(x, bundled_vector) for bundled_vector in bundled_vectors]\n",
        "        predicted_class = similarities.index(max(similarities))\n",
        "        if predicted_class == y_test[i]:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "        accuracy = correct / total * 100\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "    results[dataset] = accuracy\n",
        "\n",
        "# Print summary of accuracies\n",
        "print(f\"Summary of accuracies for {dataset} dataset: \")\n",
        "for dataset, accuracy in results.items():\n",
        "    print(f'{dataset}: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILCdBYIMD4vG",
        "outputId": "3c2992ae-1c5a-4595-b7e6-ca3566493452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use binary HDC with manhattan distance\n",
            "/content/drive/MyDrive/encoded_data/fmnist_rff-gvsa_order8_gamma0.3_dim10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-2e09cbbbde2b>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X_train = torch.load(f'{args.data_dir}/train_hd.pt')\n",
            "<ipython-input-6-2e09cbbbde2b>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  y_train = torch.load(f'{args.data_dir}/y_train.pt')\n",
            "<ipython-input-6-2e09cbbbde2b>:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X_test = torch.load(f'{args.data_dir}/test_hd.pt')\n",
            "<ipython-input-6-2e09cbbbde2b>:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  y_test = torch.load(f'{args.data_dir}/y_test.pt')\n",
            "100%|██████████| 10000/10000 [00:24<00:00, 402.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 73.13%\n",
            "/content/drive/MyDrive/encoded_data/mnist_rff-gvsa_order8_gamma0.3_dim10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:24<00:00, 408.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 84.44%\n",
            "/content/drive/MyDrive/encoded_data/isolet_rff-gvsa_order8_gamma0.3_dim10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1559/1559 [00:10<00:00, 154.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 87.49%\n",
            "/content/drive/MyDrive/encoded_data/ucihar_rff-gvsa_order8_gamma0.3_dim10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2947/2947 [00:03<00:00, 746.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 80.66%\n",
            "Summary of accuracies for ucihar dataset: \n",
            "fmnist: 73.13%\n",
            "mnist: 84.44%\n",
            "isolet: 87.49%\n",
            "ucihar: 80.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}